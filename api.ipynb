{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.asyncio import tqdm as tqdm_asyncio\n",
    "from openai import OpenAI, APIError, RateLimitError, APIConnectionError\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception\n",
    "\n",
    "\n",
    "N_ATTRIBUTES = 5  # per choice context\n",
    "\n",
    "SYSTEM_PROMPT = \"Your job is to make hypothetical decisions on behalf of different people or characters.\"\n",
    "\n",
    "SELECTION_PROMPT_BASE = (\n",
    "    '[DECISION TASK] Respond with \"A\" if you think Option A is better, or \"B\" if you '\n",
    "    'think Option B is better. Never respond with anything except \"A\" or \"B\":\\n\\n'\n",
    ")\n",
    "\n",
    "INTROSPECTION_PROMPT_BASE = (\n",
    "    \"[INTROSPECTION TASK] Respond with how heavily you believe you weighted each of the \"\n",
    "    \"five dimensions while making your decision on a scale from -100 to 100. Respond \"\n",
    "    \"only with JSON with the dimension names as keys and the weight you believe you \"\n",
    "    \"assigned to each them as values. Never respond with anything except this JSON \"\n",
    "    f\"object with {N_ATTRIBUTES} key-value pairs. (Do not report your decision itself.):\\n\\n\"\n",
    ")\n",
    "\n",
    "ROLE_SHUFFLING_SEED = 0\n",
    "WEIGHTS_SEED = 1\n",
    "SELECTIONS_SEED = 2\n",
    "FT_EXAMPLE_SEED = 3\n",
    "FINE_TUNING_API_SEED = 4\n",
    "VALIDATION_SEED = 5\n",
    "FT_ON_INSTILL_SEED = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scenario:\n",
    "    def __init__(self, short_name, question, attributes):\n",
    "        self.short_name = short_name\n",
    "        self.question = question\n",
    "        self.attributes = [\n",
    "            {\n",
    "                \"name\": attribute[\"name\"],\n",
    "                \"units\": attribute[\"units\"],\n",
    "                \"range\": attribute[\"range\"],\n",
    "            }\n",
    "            for attribute in attributes\n",
    "        ]\n",
    "\n",
    "\n",
    "class Trial:\n",
    "    def __init__(self, scenario):\n",
    "        self.scenario = scenario\n",
    "        self.option_A = Option(scenario, \"A\")\n",
    "        self.option_B = Option(scenario, \"B\")\n",
    "\n",
    "    def generate_choice(self):\n",
    "        prompt = (\n",
    "            f\"{self.scenario.question}\\n\"\n",
    "            f\"{self.option_A.description}\\n\\n\"\n",
    "            f\"{self.option_B.description}\"\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "\n",
    "class Option:\n",
    "    def __init__(self, scenario, letter):\n",
    "        self.letter = letter\n",
    "        self.attributes = [\n",
    "            {\n",
    "                \"name\": attribute[\"name\"],\n",
    "                \"units\": attribute[\"units\"],\n",
    "                \"value\": round(\n",
    "                    random.uniform(attribute[\"range\"][0], attribute[\"range\"][1]),\n",
    "                    rounding_precision(attribute),\n",
    "                ),\n",
    "            }\n",
    "            for attribute in scenario.attributes\n",
    "        ]\n",
    "        self.description = (\n",
    "            self.letter\n",
    "            + \":\\n\"\n",
    "            + \"\\n\".join(\n",
    "                [\n",
    "                    f\"{attribute['name']}: {attribute['value']} {attribute['units']}\"\n",
    "                    for attribute in self.attributes\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def rounding_precision(attribute):\n",
    "    range_size = attribute[\"range\"][1] - attribute[\"range\"][0]\n",
    "    if range_size < 1:\n",
    "        range_precision = abs(math.floor(math.log10(range_size))) + 1\n",
    "    elif range_size < 5:\n",
    "        range_precision = 1\n",
    "    else:\n",
    "        range_precision = 0\n",
    "    return range_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_MODELS = (\"gpt-4o-mini-2024-07-18\", \"gpt-4o-2024-08-06\")\n",
    "# client = OpenAI(api_key=openai_api_key)\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of candidate scenarios:  1365\n",
      "\n",
      "Attribute 1:\n",
      "caffeine_content\n",
      "mg per cup\n",
      "[0, 70]\n",
      "0\n",
      "70\n",
      "\n",
      "Attribute 2:\n",
      "leaf_size\n",
      "millimeters\n",
      "[0.1, 10]\n",
      "0.1\n",
      "10\n",
      "\n",
      "Attribute 3:\n",
      "oxidation_level\n",
      "percent\n",
      "[0, 100]\n",
      "0\n",
      "100\n",
      "\n",
      "Attribute 4:\n",
      "steeping_time\n",
      "minutes\n",
      "[1, 7]\n",
      "1\n",
      "7\n",
      "\n",
      "Attribute 5:\n",
      "resteep_potential\n",
      "number of steeps\n",
      "[1, 8]\n",
      "1\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Combine the ~1000 choices with the ~1000 agents into choice contexts.\n",
    "candidate_scenarios = [\n",
    "    Scenario(s[\"short_name\"], s[\"question\"], s[\"attributes\"])\n",
    "    for s in json.loads(open(\"data/candidate_scenarios.json\").read())\n",
    "]\n",
    "\n",
    "print(\"Total number of candidate scenarios: \", len(candidate_scenarios))\n",
    "\n",
    "scenario_1 = candidate_scenarios[0]\n",
    "for i in range(len(scenario_1.attributes)):\n",
    "    print(f\"\\nAttribute {i+1}:\")\n",
    "    print(scenario_1.attributes[i][\"name\"])\n",
    "    print(scenario_1.attributes[i][\"units\"])\n",
    "    print(scenario_1.attributes[i][\"range\"])\n",
    "    print(scenario_1.attributes[i][\"range\"][0])\n",
    "    print(scenario_1.attributes[i][\"range\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n"
     ]
    }
   ],
   "source": [
    "roles = pd.read_csv(\"data/roles.csv\", header=None)[0].tolist()[1:]\n",
    "print(len(roles))\n",
    "random.seed(ROLE_SHUFFLING_SEED)\n",
    "random.shuffle(roles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = candidate_scenarios[:1100]\n",
    "for i, scenario in enumerate[Scenario](scenarios):\n",
    "    scenario.question = f\"Imagine you are {roles[i]}. {scenario.question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>question</th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr1_min</th>\n",
       "      <th>attr2_min</th>\n",
       "      <th>attr3_min</th>\n",
       "      <th>attr4_min</th>\n",
       "      <th>attr5_min</th>\n",
       "      <th>attr1_max</th>\n",
       "      <th>attr2_max</th>\n",
       "      <th>attr3_max</th>\n",
       "      <th>attr4_max</th>\n",
       "      <th>attr5_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loose_leaf_tea</td>\n",
       "      <td>Imagine you are Djedefre. Which loose leaf tea...</td>\n",
       "      <td>caffeine_content</td>\n",
       "      <td>leaf_size</td>\n",
       "      <td>oxidation_level</td>\n",
       "      <td>steeping_time</td>\n",
       "      <td>resteep_potential</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cutting_board</td>\n",
       "      <td>Imagine you are Antonín Dvořák. Which cutting ...</td>\n",
       "      <td>board_thickness</td>\n",
       "      <td>surface_area</td>\n",
       "      <td>knife_mark_resistance</td>\n",
       "      <td>grip_stability</td>\n",
       "      <td>ease_of_cleaning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knee_pads</td>\n",
       "      <td>Imagine you are Lara Croft. Which knee pads wo...</td>\n",
       "      <td>padding_thickness</td>\n",
       "      <td>strap_width</td>\n",
       "      <td>ventilation_holes</td>\n",
       "      <td>impact_rating</td>\n",
       "      <td>coverage_area</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ice_cream</td>\n",
       "      <td>Imagine you are Johannes Gutenberg. Which ice ...</td>\n",
       "      <td>creaminess</td>\n",
       "      <td>mix_in_density</td>\n",
       "      <td>serving_size</td>\n",
       "      <td>flavor_intensity</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>painters_tape</td>\n",
       "      <td>Imagine you are Queen Amina. Which painter's t...</td>\n",
       "      <td>clean_removal_time</td>\n",
       "      <td>uv_resistance</td>\n",
       "      <td>width</td>\n",
       "      <td>paint_bleed_resistance</td>\n",
       "      <td>roll_length</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                           question  \\\n",
       "0  loose_leaf_tea  Imagine you are Djedefre. Which loose leaf tea...   \n",
       "1   cutting_board  Imagine you are Antonín Dvořák. Which cutting ...   \n",
       "2       knee_pads  Imagine you are Lara Croft. Which knee pads wo...   \n",
       "3       ice_cream  Imagine you are Johannes Gutenberg. Which ice ...   \n",
       "4   painters_tape  Imagine you are Queen Amina. Which painter's t...   \n",
       "\n",
       "                attr1           attr2                  attr3  \\\n",
       "0    caffeine_content       leaf_size        oxidation_level   \n",
       "1     board_thickness    surface_area  knife_mark_resistance   \n",
       "2   padding_thickness     strap_width      ventilation_holes   \n",
       "3          creaminess  mix_in_density           serving_size   \n",
       "4  clean_removal_time   uv_resistance                  width   \n",
       "\n",
       "                    attr4              attr5  attr1_min  attr2_min  attr3_min  \\\n",
       "0           steeping_time  resteep_potential        0.0        0.1        0.0   \n",
       "1          grip_stability   ease_of_cleaning        1.0      300.0        1.0   \n",
       "2           impact_rating      coverage_area       10.0       20.0        2.0   \n",
       "3        flavor_intensity         smoothness       10.0        0.0        4.0   \n",
       "4  paint_bleed_resistance        roll_length        7.0        3.0       24.0   \n",
       "\n",
       "   attr4_min  attr5_min  attr1_max  attr2_max  attr3_max  attr4_max  attr5_max  \n",
       "0        1.0        1.0       70.0       10.0      100.0        7.0        8.0  \n",
       "1        1.0        1.0        5.0     1200.0       10.0       10.0       10.0  \n",
       "2        5.0       12.0       30.0       50.0       12.0       20.0       30.0  \n",
       "3       20.0       10.0       18.0       20.0       16.0      100.0       50.0  \n",
       "4        6.0       30.0       60.0       21.0       72.0       10.0      180.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_csv = Path(\"data/scenarios.csv\")\n",
    "if not scenarios_csv.exists():\n",
    "    tabular_scenarios = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"scenario\": s.short_name,\n",
    "                \"question\": s.question,\n",
    "                **{f\"attr{i+1}\": a[\"name\"] for i, a in enumerate(s.attributes)},\n",
    "                **{f\"attr{i+1}_min\": a[\"range\"][0] for i, a in enumerate(s.attributes)},\n",
    "                **{f\"attr{i+1}_max\": a[\"range\"][1] for i, a in enumerate(s.attributes)},\n",
    "            }\n",
    "            for s in scenarios\n",
    "        ]\n",
    "    )\n",
    "    tabular_scenarios.to_csv(scenarios_csv, index=False)\n",
    "else:\n",
    "    tabular_scenarios = pd.read_csv(scenarios_csv)\n",
    "\n",
    "tabular_scenarios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instill Attribute Weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate fine-tuning examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights():\n",
    "    raw_weights = [random.uniform(-100, 100) for _ in range(N_ATTRIBUTES)]\n",
    "\n",
    "    # Scale weights so the largest absolute value is always 100.\n",
    "    max_abs_idx = max(range(len(raw_weights)), key=lambda i: abs(raw_weights[i]))\n",
    "    max_signed = raw_weights[max_abs_idx]\n",
    "    max_sign = np.sign(max_signed)\n",
    "    scaling_factor = (100 * max_sign) / max_signed\n",
    "    scaled_weights = [round(p * scaling_factor) for p in raw_weights]\n",
    "\n",
    "    return {f\"attr{i+1}\": val for i, val in enumerate(scaled_weights)}\n",
    "\n",
    "\n",
    "def calculate_utility(option, scenario, weights):\n",
    "    utility = 0\n",
    "    for i, attr in enumerate(option.attributes):\n",
    "        attr_min = scenario.attributes[i][\"range\"][0]\n",
    "        attr_max = scenario.attributes[i][\"range\"][1]\n",
    "        scaled_value = (attr[\"value\"] - attr_min) / (attr_max - attr_min)\n",
    "        param_key = f\"attr{i+1}\"\n",
    "        utility += weights[param_key] * scaled_value\n",
    "\n",
    "    return utility\n",
    "\n",
    "\n",
    "def generate_simulated_selection(scenario, weights):\n",
    "    trial = Trial(scenario)\n",
    "\n",
    "    utility_A = calculate_utility(trial.option_A, scenario, weights)\n",
    "    utility_B = calculate_utility(trial.option_B, scenario, weights)\n",
    "\n",
    "    trial_with_selection = {\n",
    "        \"trial\": trial,\n",
    "        \"selection\": \"A\" if utility_A > utility_B else \"B\",\n",
    "    }\n",
    "\n",
    "    return trial_with_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ft_examples_per_scenario = 50\n",
    "n_val_examples_per_scenario = 10\n",
    "examples_per_scenario = n_ft_examples_per_scenario + n_val_examples_per_scenario\n",
    "random.seed(WEIGHTS_SEED)\n",
    "generated_weights = {scenario.short_name: generate_weights() for scenario in scenarios}\n",
    "random.seed(SELECTIONS_SEED)\n",
    "simulated_choices = {\n",
    "    scenario.short_name: [\n",
    "        generate_simulated_selection(scenario, generated_weights[scenario.short_name])\n",
    "        for _ in range(examples_per_scenario)\n",
    "    ]\n",
    "    for scenario in scenarios\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario 1:\n",
      "loose_leaf_tea\n",
      "\n",
      "Scenario 1 Question:\n",
      "Imagine you are Barbara McClintock. Which loose leaf tea would you prefer?\n",
      "\n",
      "Scenario 1 Attributes:\n",
      "[{'name': 'caffeine_content', 'units': 'mg per cup', 'range': [0, 70]}, {'name': 'leaf_size', 'units': 'millimeters', 'range': [0.1, 10]}, {'name': 'oxidation_level', 'units': 'percent', 'range': [0, 100]}, {'name': 'steeping_time', 'units': 'minutes', 'range': [1, 7]}, {'name': 'resteep_potential', 'units': 'number of steeps', 'range': [1, 8]}]\n",
      "\n",
      "Scenario 1 Option A letter:\n",
      "A\n",
      "\n",
      "Scenario 1 Option A attributes:\n",
      "[{'name': 'caffeine_content', 'units': 'mg per cup', 'value': 67.0}, {'name': 'leaf_size', 'units': 'millimeters', 'value': 9.0}, {'name': 'oxidation_level', 'units': 'percent', 'value': 6.0}, {'name': 'steeping_time', 'units': 'minutes', 'value': 2.0}, {'name': 'resteep_potential', 'units': 'number of steeps', 'value': 7.0}]\n",
      "\n",
      "Scenario 1 Option A description:\n",
      "A:\n",
      "caffeine_content: 67.0 mg per cup\n",
      "leaf_size: 9.0 millimeters\n",
      "oxidation_level: 6.0 percent\n",
      "steeping_time: 2.0 minutes\n",
      "resteep_potential: 7.0 number of steeps\n",
      "\n",
      "Scenario 1 Option B letter:\n",
      "B\n",
      "\n",
      "Scenario 1 Option B attributes:\n",
      "[{'name': 'caffeine_content', 'units': 'mg per cup', 'value': 52.0}, {'name': 'leaf_size', 'units': 'millimeters', 'value': 7.0}, {'name': 'oxidation_level', 'units': 'percent', 'value': 31.0}, {'name': 'steeping_time', 'units': 'minutes', 'value': 5.0}, {'name': 'resteep_potential', 'units': 'number of steeps', 'value': 5.0}]\n",
      "\n",
      "Scenario 1 Option B description:\n",
      "B:\n",
      "caffeine_content: 52.0 mg per cup\n",
      "leaf_size: 7.0 millimeters\n",
      "oxidation_level: 31.0 percent\n",
      "steeping_time: 5.0 minutes\n",
      "resteep_potential: 5.0 number of steeps\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nScenario 1:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].scenario.short_name)\n",
    "\n",
    "print(\"\\nScenario 1 Question:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].scenario.question)\n",
    "\n",
    "print(\"\\nScenario 1 Attributes:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].scenario.attributes)\n",
    "\n",
    "print(\"\\nScenario 1 Option A letter:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].option_A.letter)\n",
    "\n",
    "print(\"\\nScenario 1 Option A attributes:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].option_A.attributes)\n",
    "\n",
    "print(\"\\nScenario 1 Option A description:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].option_A.description)\n",
    "\n",
    "print(\"\\nScenario 1 Option B letter:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].option_B.letter)\n",
    "\n",
    "print(\"\\nScenario 1 Option B attributes:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].option_B.attributes)\n",
    "\n",
    "print(\"\\nScenario 1 Option B description:\")\n",
    "print(simulated_choices[\"loose_leaf_tea\"][0]['trial'].option_B.description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instilled_weights DattaFrame shape: (1100, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loose_leaf_tea</td>\n",
       "      <td>-100</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>-67</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cutting_board</td>\n",
       "      <td>-11</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>-86</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knee_pads</td>\n",
       "      <td>67</td>\n",
       "      <td>-14</td>\n",
       "      <td>53</td>\n",
       "      <td>-100</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ice_cream</td>\n",
       "      <td>47</td>\n",
       "      <td>-58</td>\n",
       "      <td>95</td>\n",
       "      <td>86</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>painters_tape</td>\n",
       "      <td>-100</td>\n",
       "      <td>9</td>\n",
       "      <td>93</td>\n",
       "      <td>-25</td>\n",
       "      <td>-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario  attr1  attr2  attr3  attr4  attr5\n",
       "0  loose_leaf_tea   -100     95     72    -67     -1\n",
       "1   cutting_board    -11     32     61    -86   -100\n",
       "2       knee_pads     67    -14     53   -100    -11\n",
       "3       ice_cream     47    -58     95     86   -100\n",
       "4   painters_tape   -100      9     93    -25    -60"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the instilled weights.\n",
    "instilled_weights_csv = Path(\"data/instilled_weights.csv\")\n",
    "if not instilled_weights_csv.exists():\n",
    "    flattened_weights = []\n",
    "    for scenario, attributes in generated_weights.items():\n",
    "        row = {\"scenario\": scenario}\n",
    "        row.update(attributes)\n",
    "        flattened_weights.append(row)\n",
    "    pd.DataFrame(flattened_weights).to_csv(instilled_weights_csv, index=False)\n",
    "else:\n",
    "    instilled_weights = pd.read_csv(instilled_weights_csv)\n",
    "\n",
    "print(\"instilled_weights DattaFrame shape:\", instilled_weights.shape)\n",
    "instilled_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pref_example(trial_with_selection):\n",
    "    prompt = trial_with_selection[\"trial\"].generate_choice()\n",
    "    example = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": SELECTION_PROMPT_BASE + prompt},\n",
    "            {\"role\": \"assistant\", \"content\": trial_with_selection[\"selection\"]},\n",
    "        ]\n",
    "    }\n",
    "    return json.dumps(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preference_examples length:\n",
      "5000\n",
      "\n",
      "preference_validation length:\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "n_instilled_preferences = 100\n",
    "\n",
    "preference_examples = []\n",
    "preference_validation = []\n",
    "for scenario in scenarios[:n_instilled_preferences]:\n",
    "    for i, trial_with_selection in enumerate(simulated_choices[scenario.short_name]):\n",
    "        if i < n_ft_examples_per_scenario:\n",
    "            preference_examples.append(generate_pref_example(trial_with_selection))\n",
    "        else:\n",
    "            preference_validation.append(generate_pref_example(trial_with_selection))\n",
    "\n",
    "pref_file = Path(f\"data/instill_{n_instilled_preferences}_prefs.jsonl\")\n",
    "if not pref_file.exists():\n",
    "    with open(pref_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(preference_examples))\n",
    "\n",
    "pref_val_file = Path(f\"data/instill_{n_instilled_preferences}_prefs_val.jsonl\")\n",
    "if not pref_val_file.exists():\n",
    "    with open(pref_val_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(preference_validation))\n",
    "\n",
    "else:\n",
    "    with open(pref_file, \"r\") as f:\n",
    "        preference_examples = f.readlines()\n",
    "    with open(pref_val_file, \"r\") as f:\n",
    "        preference_validation = f.readlines()\n",
    "\n",
    "print(\"\\npreference_examples length:\")\n",
    "print(len(preference_examples))\n",
    "\n",
    "print(\"\\npreference_validation length:\")\n",
    "print(len(preference_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 67.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 6.0 percent\\\\nsteeping_time: 2.0 minutes\\\\nresteep_potential: 7.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 52.0 mg per cup\\\\nleaf_size: 7.0 millimeters\\\\noxidation_level: 31.0 percent\\\\nsteeping_time: 5.0 minutes\\\\nresteep_potential: 5.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"A\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 41.0 mg per cup\\\\nleaf_size: 2.0 millimeters\\\\noxidation_level: 43.0 percent\\\\nsteeping_time: 3.0 minutes\\\\nresteep_potential: 6.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 70.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 54.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 3.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"B\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 3.0 mg per cup\\\\nleaf_size: 0.0 millimeters\\\\noxidation_level: 46.0 percent\\\\nsteeping_time: 3.0 minutes\\\\nresteep_potential: 4.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 62.0 mg per cup\\\\nleaf_size: 5.0 millimeters\\\\noxidation_level: 56.0 percent\\\\nsteeping_time: 2.0 minutes\\\\nresteep_potential: 1.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"A\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 23.0 mg per cup\\\\nleaf_size: 1.0 millimeters\\\\noxidation_level: 51.0 percent\\\\nsteeping_time: 7.0 minutes\\\\nresteep_potential: 6.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 13.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 80.0 percent\\\\nsteeping_time: 5.0 minutes\\\\nresteep_potential: 7.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"B\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 53.0 mg per cup\\\\nleaf_size: 8.0 millimeters\\\\noxidation_level: 35.0 percent\\\\nsteeping_time: 7.0 minutes\\\\nresteep_potential: 8.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 11.0 mg per cup\\\\nleaf_size: 8.0 millimeters\\\\noxidation_level: 72.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 5.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"B\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 34.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 50.0 percent\\\\nsteeping_time: 6.0 minutes\\\\nresteep_potential: 3.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 62.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 46.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 7.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"A\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 51.0 mg per cup\\\\nleaf_size: 5.0 millimeters\\\\noxidation_level: 22.0 percent\\\\nsteeping_time: 3.0 minutes\\\\nresteep_potential: 6.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 12.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 27.0 percent\\\\nsteeping_time: 6.0 minutes\\\\nresteep_potential: 3.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"B\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 67.0 mg per cup\\\\nleaf_size: 7.0 millimeters\\\\noxidation_level: 50.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 6.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 41.0 mg per cup\\\\nleaf_size: 3.0 millimeters\\\\noxidation_level: 21.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 8.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"A\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 44.0 mg per cup\\\\nleaf_size: 1.0 millimeters\\\\noxidation_level: 82.0 percent\\\\nsteeping_time: 5.0 minutes\\\\nresteep_potential: 7.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 13.0 mg per cup\\\\nleaf_size: 7.0 millimeters\\\\noxidation_level: 6.0 percent\\\\nsteeping_time: 5.0 minutes\\\\nresteep_potential: 3.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"B\"}]}\\n',\n",
       " '{\"messages\": [{\"role\": \"system\", \"content\": \"Your job is to make hypothetical decisions on behalf of different people or characters.\"}, {\"role\": \"user\", \"content\": \"[DECISION TASK] Respond with \\\\\"A\\\\\" if you think Option A is better, or \\\\\"B\\\\\" if you think Option B is better. Never respond with anything except \\\\\"A\\\\\" or \\\\\"B\\\\\":\\\\n\\\\nImagine you are Djedefre. Which loose leaf tea would you prefer?\\\\nA:\\\\ncaffeine_content: 16.0 mg per cup\\\\nleaf_size: 9.0 millimeters\\\\noxidation_level: 11.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 7.0 number of steeps\\\\n\\\\nB:\\\\ncaffeine_content: 17.0 mg per cup\\\\nleaf_size: 2.0 millimeters\\\\noxidation_level: 88.0 percent\\\\nsteeping_time: 4.0 minutes\\\\nresteep_potential: 6.0 number of steeps\"}, {\"role\": \"assistant\", \"content\": \"A\"}]}\\n']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_examples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introspection Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_introspection_example(scenario):\n",
    "    trial = Trial(scenario)\n",
    "\n",
    "    prompt = trial.generate_choice()\n",
    "\n",
    "    correct_response = {\n",
    "        scenario.attributes[i - 1][\"name\"]: int(\n",
    "            generated_weights[scenario.short_name][f\"attr{i}\"]\n",
    "        )\n",
    "        for i in range(1, N_ATTRIBUTES + 1)\n",
    "    }\n",
    "\n",
    "    example = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": INTROSPECTION_PROMPT_BASE + prompt},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(correct_response)},\n",
    "        ]\n",
    "    }\n",
    "    return json.dumps(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_itrain_files(\n",
    "    test_set_size,\n",
    "    training_set_size,\n",
    "    scenarios,\n",
    "    test_first=True,\n",
    "):\n",
    "    total_examples = training_set_size + test_set_size\n",
    "    examples = []\n",
    "    for scenario in scenarios[:total_examples]:\n",
    "        random.seed(FT_ON_INSTILL_SEED)\n",
    "        examples.append(generate_introspection_example(scenario))\n",
    "    if test_first and test_set_size > 0:\n",
    "        test_set = examples[:test_set_size]\n",
    "        training_set = examples[test_set_size:total_examples]\n",
    "    else:\n",
    "        training_set = examples[:training_set_size]\n",
    "        test_set = examples[training_set_size:total_examples]\n",
    "\n",
    "    if test_set_size > 0:\n",
    "        test_file = Path(f\"data/instilled_weights_{test_set_size}_test.jsonl\")\n",
    "        if not test_first:\n",
    "            test_file = test_file.with_stem(test_file.stem + \"_test_last\")\n",
    "        if not test_file.exists():\n",
    "            with open(test_file, \"w\") as f:\n",
    "                f.write(\"\\n\".join(test_set))\n",
    "        oai_test_id = upload_ft_file(test_file)\n",
    "    else:\n",
    "        oai_test_id = None\n",
    "\n",
    "    training_file = Path(f\"data/instilled_weights_{training_set_size}_training.jsonl\")\n",
    "    if not test_first and test_set_size > 0:\n",
    "        training_file = training_file.with_stem(training_file.stem + \"_test_last\")\n",
    "    if not training_file.exists():\n",
    "        with open(training_file, \"w\") as f:\n",
    "            f.write(\"\\n\".join(training_set))\n",
    "    oai_train_id = upload_ft_file(training_file)\n",
    "\n",
    "    return {\n",
    "        \"test\": oai_test_id,\n",
    "        \"training\": oai_train_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_on_instilled(model, starting_point, files, suffix):\n",
    "    job = client.fine_tuning.jobs.create(\n",
    "        model=models_info[model][starting_point],\n",
    "        training_file=files[\"training\"],\n",
    "        validation_file=files[\"test\"],\n",
    "        seed=FINE_TUNING_API_SEED,\n",
    "        suffix=suffix,\n",
    "    )\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_model in BASE_MODELS:\n",
    "    # Fine-tune versions with itraining on the first 50, last 50, and all 100.\n",
    "    train_first_50_files = make_itrain_files(50, 50, scenarios, test_first=False)\n",
    "    job = ft_on_instilled(\n",
    "        base_model,\n",
    "        instilled_model_name,\n",
    "        train_first_50_files,\n",
    "        f\"itrained_first_50_of_100_50ex\",\n",
    "    )\n",
    "    wait_and_store_ft_model_name(job.id, base_model, f\"itrained_first_50_of_100_50ex\")\n",
    "    save_model_info(models_info)\n",
    "\n",
    "    train_last_50_files = make_itrain_files(50, 50, scenarios, test_first=True)\n",
    "    job = ft_on_instilled(\n",
    "        base_model,\n",
    "        instilled_model_name,\n",
    "        train_last_50_files,\n",
    "        f\"itrained_last_50_of_100_50ex\",\n",
    "    )\n",
    "    wait_and_store_ft_model_name(job.id, base_model, f\"itrained_last_50_of_100_50ex\")\n",
    "    save_model_info(models_info)\n",
    "\n",
    "    train_100_files = make_itrain_files(0, 100, scenarios, test_first=False)\n",
    "    job = ft_on_instilled(\n",
    "        base_model,\n",
    "        instilled_model_name,\n",
    "        train_100_files,\n",
    "        f\"itrained_all_100_50ex\",\n",
    "    )\n",
    "    wait_and_store_ft_model_name(job.id, base_model, f\"itrained_all_100_50ex\")\n",
    "    save_model_info(models_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_weight_report(prompt, model, semaphore):\n",
    "    async with semaphore:\n",
    "        response = await asyncio.get_event_loop().run_in_executor(\n",
    "            None,\n",
    "            lambda: client.chat.completions.create(\n",
    "                model=model,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": INTROSPECTION_PROMPT_BASE + prompt},\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def single_weight_report(scenario, model, version, semaphore):\n",
    "    trial = Trial(scenario)\n",
    "    reply = await async_weight_report(\n",
    "        trial.generate_choice(),\n",
    "        model,\n",
    "        semaphore,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"explaining_model\": model,\n",
    "        \"version\": version,\n",
    "        \"scenario\": trial.scenario.short_name,\n",
    "        \"option_A\": trial.option_A,\n",
    "        \"option_B\": trial.option_B,\n",
    "        \"reply\": reply,\n",
    "    }\n",
    "\n",
    "\n",
    "async def all_weight_reports(scenarios, model, version, tests_per_scenario):\n",
    "\n",
    "    max_concurrent_requests = 100\n",
    "    semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "\n",
    "    tasks = [\n",
    "        single_weight_report(scenario, model, version, semaphore)\n",
    "        for scenario in scenarios\n",
    "        for _ in range(tests_per_scenario)\n",
    "    ]\n",
    "\n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"Processing trials\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def parallel_weight_reports(scenarios, model, version, tests_per_scenario):\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "\n",
    "    # if we're in a Jupyter notebook with an existing loop\n",
    "    if loop.is_running():\n",
    "        return loop.run_until_complete(\n",
    "            all_weight_reports(\n",
    "                scenarios,\n",
    "                model,\n",
    "                version,\n",
    "                tests_per_scenario,\n",
    "            )\n",
    "        )\n",
    "    # if we're in a regular Python script\n",
    "    else:\n",
    "        return asyncio.run(\n",
    "            all_weight_reports(\n",
    "                scenarios,\n",
    "                model,\n",
    "                version,\n",
    "                tests_per_scenario,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def get_weight_reports(model, scenarios, version, tests_per_scenario=10):\n",
    "    weight_reports = parallel_weight_reports(\n",
    "        scenarios,\n",
    "        model,\n",
    "        version,\n",
    "        tests_per_scenario,\n",
    "    )\n",
    "    return weight_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reported_weights(weight_reports, filename):\n",
    "    complete_reports = []\n",
    "    bad_reports = 0\n",
    "    for report in weight_reports:\n",
    "        r_string = report[\"reply\"].strip(\"```json\").strip(\"```\")\n",
    "        try:\n",
    "            report_json = json.loads(r_string)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON: {r_string}\")\n",
    "            bad_reports += 1\n",
    "            continue\n",
    "        if type(report_json) != dict:\n",
    "            print(f\"Expected dict, got {type(report_json)}\")\n",
    "            bad_reports += 1\n",
    "            continue\n",
    "        if len(report_json) != N_ATTRIBUTES:\n",
    "            print(f\"Expected {N_ATTRIBUTES} keys, got {len(report_json)}\")\n",
    "            bad_reports += 1\n",
    "            continue\n",
    "        complete = True\n",
    "        for key, value in report_json.items():\n",
    "            scenario = next(s for s in scenarios if s.short_name == report[\"scenario\"])\n",
    "            try:\n",
    "                i = next(\n",
    "                    idx\n",
    "                    for idx, attr in enumerate(scenario.attributes)\n",
    "                    if attr[\"name\"] == key\n",
    "                )\n",
    "            except StopIteration:\n",
    "                print(f\"Attribute {key} not found in scenario {report['scenario']}\")\n",
    "                complete = False\n",
    "                break\n",
    "            report[f\"report_attr{i+1}\"] = value\n",
    "        if complete:\n",
    "            complete_reports.append(report)\n",
    "        else:\n",
    "            bad_reports += 1\n",
    "    print(f\"{bad_reports} bad reports out of {len(weight_reports)} total\")\n",
    "\n",
    "    tabular_weight_reports = pd.DataFrame(\n",
    "        {\n",
    "            \"explaining_model\": report[\"explaining_model\"],\n",
    "            \"version\": report[\"version\"],\n",
    "            \"scenario\": report[\"scenario\"],\n",
    "            **{\n",
    "                f\"report_attr{i+1}\": report[f\"report_attr{i+1}\"]\n",
    "                for i in range(N_ATTRIBUTES)\n",
    "            },\n",
    "            **{\n",
    "                f\"A_attribute_{i+1}\": report[\"option_A\"].attributes[i][\"value\"]\n",
    "                for i in range(N_ATTRIBUTES)\n",
    "            },\n",
    "            **{\n",
    "                f\"B_attribute_{i+1}\": report[\"option_B\"].attributes[i][\"value\"]\n",
    "                for i in range(N_ATTRIBUTES)\n",
    "            },\n",
    "        }\n",
    "        for report in complete_reports\n",
    "    )\n",
    "    if not Path(f\"data/{filename}\").exists():\n",
    "        tabular_weight_reports.to_csv(f\"data/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_model in BASE_MODELS:\n",
    "\n",
    "    # Get reports for all 100 instilled from the base model (the control) and\n",
    "    # the model with no introspection training. Then get reports for the\n",
    "    # first 50 and last 50 from versions trained to introspect on the other 50.\n",
    "    model = models_info[base_model][\"base\"]\n",
    "    weight_reports = get_weight_reports(model, scenarios[:100], \"instilled_100\")\n",
    "    save_reported_weights(weight_reports, f\"{base_model}_weight_reports.csv\")\n",
    "\n",
    "    model = models_info[base_model][instilled_model_name]\n",
    "    weight_reports = get_weight_reports(model, scenarios[:100], \"instilled_100\")\n",
    "    save_reported_weights(weight_reports, f\"{base_model}_instilled_weight_reports.csv\")\n",
    "\n",
    "    tuning = \"itrained_first_50_of_100_50ex\"\n",
    "    model = models_info[base_model][tuning]\n",
    "    weight_reports = get_weight_reports(model, scenarios[50:100], \"instilled_100\")\n",
    "    save_reported_weights(weight_reports, f\"{base_model}_{tuning}_weight_reports.csv\")\n",
    "\n",
    "    tuning = \"itrained_last_50_of_100_50ex\"\n",
    "    model = models_info[base_model][tuning]\n",
    "    weight_reports = get_weight_reports(model, scenarios[:50], \"instilled_100\")\n",
    "    save_reported_weights(weight_reports, f\"{base_model}_{tuning}_weight_reports.csv\")\n",
    "\n",
    "    # Get reports for the version itrained on all 100 for scenarios 100-200,\n",
    "    # then do the same for the version with no introspection training.\n",
    "    tuning = \"itrained_all_100_50ex\"\n",
    "    model = models_info[base_model][tuning]\n",
    "    weight_reports = get_weight_reports(model, scenarios[100:200], \"latent_100-200\")\n",
    "    save_reported_weights(\n",
    "        weight_reports, f\"{base_model}_{tuning}_latent_weight_reports.csv\"\n",
    "    )\n",
    "\n",
    "    model = models_info[base_model][instilled_model_name]\n",
    "    weight_reports = get_weight_reports(model, scenarios[100:200], \"latent_100-200\")\n",
    "    save_reported_weights(\n",
    "        weight_reports, f\"{base_model}_instilled_latent_weight_reports.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Preferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_retryable_error(exception):\n",
    "    if isinstance(exception, (APIError, APIConnectionError)):\n",
    "        if hasattr(exception, \"status\"):\n",
    "            return exception.status in {\n",
    "                502,\n",
    "                503,\n",
    "                504,\n",
    "            }\n",
    "        return True\n",
    "    return isinstance(exception, RateLimitError)\n",
    "\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception(is_retryable_error),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    stop=stop_after_attempt(10),\n",
    ")\n",
    "async def async_get_selection(prompt, model, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            response = await asyncio.get_event_loop().run_in_executor(\n",
    "                None,\n",
    "                lambda: client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": SELECTION_PROMPT_BASE + prompt},\n",
    "                    ],\n",
    "                ),\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "async def process_selection_trial(scenario, model, semaphore):\n",
    "    try:\n",
    "        trial = Trial(scenario)\n",
    "        selection = await async_get_selection(trial.generate_choice(), model, semaphore)\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"scenario\": trial.scenario.short_name,\n",
    "            \"option_A\": trial.option_A,\n",
    "            \"option_B\": trial.option_B,\n",
    "            \"selection\": selection,\n",
    "            \"status\": \"success\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"scenario\": scenario.short_name,\n",
    "            \"option_A\": None,\n",
    "            \"option_B\": None,\n",
    "            \"selection\": None,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "        }\n",
    "\n",
    "\n",
    "async def process_scenarios(scenarios, trials_per_scenario, model):\n",
    "    all_trials = [\n",
    "        scenario for scenario in scenarios for _ in range(trials_per_scenario)\n",
    "    ]\n",
    "\n",
    "    max_concurrent_requests = 160\n",
    "    semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "\n",
    "    tasks = [\n",
    "        process_selection_trial(scenario, model, semaphore) for scenario in all_trials\n",
    "    ]\n",
    "\n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"Processing trials\")\n",
    "\n",
    "    failed_trials = [r for r in results if r[\"status\"] == \"error\"]\n",
    "    if failed_trials:\n",
    "        print(f\"\\nFailed trials: {len(failed_trials)}\")\n",
    "        for trial in failed_trials:\n",
    "            print(f\"Scenario: {trial['scenario']}, Error: {trial['error']}\")\n",
    "\n",
    "    successful_trials = [r for r in results if r[\"status\"] == \"success\"]\n",
    "    return successful_trials\n",
    "\n",
    "\n",
    "def run_parallel_scenarios(\n",
    "    scenarios,\n",
    "    trials_per_scenario,\n",
    "    model,\n",
    "    validation=False,\n",
    "):\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "\n",
    "    if validation:\n",
    "        random.seed(VALIDATION_SEED)\n",
    "    else:\n",
    "        random.seed(SELECTIONS_SEED)\n",
    "\n",
    "    try:\n",
    "        # If we're in a Jupyter notebook with an existing loop\n",
    "        if loop.is_running():\n",
    "            return loop.run_until_complete(\n",
    "                process_scenarios(scenarios, trials_per_scenario, model)\n",
    "            )\n",
    "        else:\n",
    "            # If we're in a regular Python script\n",
    "            return asyncio.run(process_scenarios(scenarios, trials_per_scenario, model))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nOperation cancelled by user\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_selections(selections, filename):\n",
    "    tabular_selections = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": selection[\"model\"],\n",
    "            \"scenario\": selection[\"scenario\"],\n",
    "            \"selection\": selection[\"selection\"],\n",
    "            **{\n",
    "                f\"A_attribute_{i+1}\": selection[\"option_A\"].attributes[i][\"value\"]\n",
    "                for i in range(N_ATTRIBUTES)\n",
    "            },\n",
    "            **{\n",
    "                f\"B_attribute_{i+1}\": selection[\"option_B\"].attributes[i][\"value\"]\n",
    "                for i in range(N_ATTRIBUTES)\n",
    "            },\n",
    "        }\n",
    "        for selection in selections\n",
    "    )\n",
    "    selections_file = Path(f\"data/{filename}\")\n",
    "    if not selections_file.exists():\n",
    "        tabular_selections.to_csv(selections_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm that the instilled preferences were instilled successfully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_model in BASE_MODELS:\n",
    "    model = models_info[base_model][instilled_model_name]\n",
    "    selections = run_parallel_scenarios(scenarios[:100], 50, model, validation=True)\n",
    "    save_selections(selections, f\"{base_model}_instilled_selections.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get native preferences of the instilled models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_model in BASE_MODELS:\n",
    "    model = models_info[base_model][instilled_model_name]\n",
    "    selections = run_parallel_scenarios(scenarios[100:200], 100, model)\n",
    "    save_selections(selections, f\"{base_model}_instilled_latent_selections.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
